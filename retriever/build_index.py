# retriever/build_index.py

import os
import json
from langchain.vectorstores import FAISS, Chroma
from langchain.schema import Document
from langchain.embeddings import HuggingFaceEmbeddings
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

# å‚æ•°é…ç½®
VECTOR_BACKEND = "faiss"  # æˆ– "chroma"
VECTOR_DIR = "retriever/vector_store"
TEXTS_PATH = os.path.join(VECTOR_DIR, "texts.jsonl")

# åµŒå…¥æ¨¡å‹ï¼ˆå¯æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ï¼‰
embedding_model = HuggingFaceEmbeddings(model_name="thenlper/gte-base")

# åˆ›å»ºå‘é‡åº“ç›®å½•ï¼ˆå¦‚ä¸å­˜åœ¨ï¼‰
os.makedirs(VECTOR_DIR, exist_ok=True)

# è¯»å–æ•™æ/çŸ¥è¯†æ®µè½
raw_texts = []
with open(TEXTS_PATH, "r", encoding="utf-8") as f:
    for line in f:
        try:
            data = json.loads(line.strip())
            raw_texts.append(data["text"])
        except:
            continue

# è½¬æ¢ä¸º langchain çš„ Document å¯¹è±¡
documents = [Document(page_content=text) for text in raw_texts]

# æ„å»ºå‘é‡åº“
print(f"ğŸ“š æ­£åœ¨å‘é‡åŒ– {len(documents)} ä¸ªçŸ¥è¯†æ®µè½...")

if VECTOR_BACKEND == "faiss":
    db = FAISS.from_documents(documents, embedding_model)
    db.save_local(VECTOR_DIR)
elif VECTOR_BACKEND == "chroma":
    db = Chroma.from_documents(documents, embedding_model, persist_directory=VECTOR_DIR)
    db.persist()
else:
    raise ValueError("Unsupported VECTOR_BACKEND")

print(f"âœ… å‘é‡ç´¢å¼•å·²æ„å»ºå®Œæ¯•ï¼Œå­˜å‚¨äºï¼š{VECTOR_DIR}")
